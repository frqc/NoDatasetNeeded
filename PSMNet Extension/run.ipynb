{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vghmoZfXMV3g",
        "outputId": "09664a82-530e-45ac-aee4-6e5acfb4dea1"
      },
      "source": [
        "!git clone https://github.com/frqc/NoDatasetNeeded.git\n",
        "%cd /content/NoDatasetNeeded/\n",
        "!git checkout  yilin\n",
        "%cd PSMNet\\ Extension"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NoDatasetNeeded'...\n",
            "remote: Enumerating objects: 181, done.\u001b[K\n",
            "remote: Counting objects: 100% (181/181), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 181 (delta 61), reused 175 (delta 55), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (181/181), 39.27 MiB | 30.16 MiB/s, done.\n",
            "Resolving deltas: 100% (61/61), done.\n",
            "/content/NoDatasetNeeded\n",
            "Branch 'yilin' set up to track remote branch 'yilin' from 'origin'.\n",
            "Switched to a new branch 'yilin'\n",
            "/content/NoDatasetNeeded/PSMNet Extension\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy94XdATqq3I",
        "outputId": "91951314-7ecd-4c51-f190-d42a7435a5c9"
      },
      "source": [
        "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_scene_flow.zip\n",
        "!unzip -q data_scene_flow.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-06 18:18:46--  https://s3.eu-central-1.amazonaws.com/avg-kitti/data_scene_flow.zip\n",
            "Resolving s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)... 52.219.75.179\n",
            "Connecting to s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)|52.219.75.179|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1681488619 (1.6G) [application/zip]\n",
            "Saving to: ‘data_scene_flow.zip’\n",
            "\n",
            "data_scene_flow.zip 100%[===================>]   1.57G  20.6MB/s    in 79s     \n",
            "\n",
            "2021-05-06 18:20:05 (20.4 MB/s) - ‘data_scene_flow.zip’ saved [1681488619/1681488619]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJjmWZT9vdSk",
        "outputId": "7e27c188-24af-4cad-df3c-9177bc65d805"
      },
      "source": [
        "!pip install reindent\n",
        "!reindent finetune.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting reindent\n",
            "  Downloading https://files.pythonhosted.org/packages/e2/21/bbfe0baec43c1d1cb1683653334b55161ccc950991c1803e17f276b5759a/reindent-3.5.1-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from reindent) (56.0.0)\n",
            "Installing collected packages: reindent\n",
            "Successfully installed reindent-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SBkEYFQ6N4o",
        "outputId": "380d15b0-3337-4b9f-db51-19c2bfc8ae83"
      },
      "source": [
        "#freeze first_two_conv_in_hourglass\n",
        "!python finetune.py --maxdisp 192 \\\n",
        "                   --model stackhourglass \\\n",
        "                   --datatype 2015 \\\n",
        "                   --datapath training/ \\\n",
        "                   --epochs 300 \\\n",
        "                   --loadmodel pretrained_sceneflow.tar \\\n",
        "                   --savemodel freeze_first_two_conv_in_hourglass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Sequential(\n",
            "  (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "  (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n",
            "ReLU(inplace=True)\n",
            "Sequential(\n",
            "  (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "  (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n",
            "ReLU(inplace=True)\n",
            "Sequential(\n",
            "  (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "  (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n",
            "ReLU(inplace=True)\n",
            "Sequential(\n",
            "  (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "  (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n",
            "Number of model parameters: 5224768\n",
            "0.001\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "epoch 1 total training loss = 2.688\n",
            "tcmalloc: large alloc 1392771072 bytes == 0x55e6f1dda000 @  0x7f6b3441db6b 0x7f6b3443d379 0x7f6ae0b3625e 0x7f6ae0b379d2 0x7f6b1d81a8e6 0x7f6b1dc7cdd9 0x7f6b1e18777a 0x7f6b1e152ef9 0x7f6b1e109657 0x7f6b1dfad929 0x7f6b2f979c07 0x7f6b2f97b584 0x7f6b2f948a8c 0x55e65b17dc25 0x55e65b13e7f2 0x55e65b1b263d 0x55e65b13fbd9 0x55e65b140231 0x55e65b1af1e6 0x55e65b1acb0e 0x55e65b13fe11 0x55e65b183029 0x55e65b140231 0x55e65b1af1e6 0x55e65b1acb0e 0x55e65b13fe11 0x55e65b140231 0x55e65b1af1e6 0x55e65b1acb0e 0x55e65b13fe11 0x55e65b183029\n",
            "tcmalloc: large alloc 1392771072 bytes == 0x55e6f1dda000 @  0x7f6b3441db6b 0x7f6b3443d379 0x7f6ae0b3625e 0x7f6ae0b379d2 0x7f6b1d81a8e6 0x7f6b1dc7cdd9 0x7f6b1e18777a 0x7f6b1e152ef9 0x7f6b1e109657 0x7f6b1dfad929 0x7f6b2f979c07 0x7f6b2f97b584 0x7f6b2f948a8c 0x55e65b17dc25 0x55e65b13e7f2 0x55e65b1b263d 0x55e65b13fbd9 0x55e65b140231 0x55e65b1af1e6 0x55e65b1acb0e 0x55e65b13fe11 0x55e65b183029 0x55e65b140231 0x55e65b1af1e6 0x55e65b1acb0e 0x55e65b13fe11 0x55e65b140231 0x55e65b1af1e6 0x55e65b1acb0e 0x55e65b13fe11 0x55e65b183029\n",
            "tcmalloc: large alloc 1392771072 bytes == 0x55e6f1dda000 @  0x7f6b3441db6b 0x7f6b3443d379 0x7f6ae0b3625e 0x7f6ae0b379d2 0x7f6b1d81a8e6 0x7f6b1dc7cdd9 0x7f6b1e18777a 0x7f6b1e152ef9 0x7f6b1e109657 0x7f6b1dfad929 0x7f6b2f979c07 0x7f6b2f97b584 0x7f6b2f948a8c 0x55e65b17dc25 0x55e65b13e7f2 0x55e65b1b263d 0x55e65b13fbd9 0x55e65b140231 0x55e65b1af1e6 0x55e65b1acb0e 0x55e65b13fe11 0x55e65b183029 0x55e65b140231 0x55e65b1af1e6 0x55e65b1acb0e 0x55e65b13fe11 0x55e65b140231 0x55e65b1af1e6 0x55e65b1acb0e 0x55e65b13fe11 0x55e65b183029\n",
            "epoch 1 total 3-px error in val = 6.373\n",
            "MAX epoch 1 total test error = 6.373\n",
            "0.001\n",
            "epoch 2 total training loss = 1.507\n",
            "epoch 2 total 3-px error in val = 5.070\n",
            "MAX epoch 1 total test error = 6.373\n",
            "0.001\n",
            "epoch 3 total training loss = 1.171\n",
            "epoch 3 total 3-px error in val = 4.898\n",
            "MAX epoch 1 total test error = 6.373\n",
            "0.001\n",
            "epoch 4 total training loss = 1.179\n",
            "epoch 4 total 3-px error in val = 4.765\n",
            "MAX epoch 1 total test error = 6.373\n",
            "0.001\n",
            "epoch 5 total training loss = 1.164\n",
            "epoch 5 total 3-px error in val = 4.746\n",
            "MAX epoch 1 total test error = 6.373\n",
            "0.001\n",
            "epoch 6 total training loss = 1.029\n",
            "epoch 6 total 3-px error in val = 4.729\n",
            "MAX epoch 1 total test error = 6.373\n",
            "0.001\n",
            "epoch 7 total training loss = 1.107\n",
            "epoch 7 total 3-px error in val = 4.641\n",
            "MAX epoch 1 total test error = 6.373\n",
            "0.001\n",
            "epoch 8 total training loss = 1.028\n",
            "epoch 8 total 3-px error in val = 4.520\n",
            "MAX epoch 1 total test error = 6.373\n",
            "0.001\n",
            "epoch 9 total training loss = 1.062\n",
            "epoch 9 total 3-px error in val = 4.621\n",
            "MAX epoch 1 total test error = 6.373\n",
            "0.001\n",
            "epoch 10 total training loss = 0.907\n",
            "epoch 10 total 3-px error in val = 4.571\n",
            "MAX epoch 1 total test error = 6.373\n",
            "0.001\n",
            "epoch 11 total training loss = 0.899\n",
            "epoch 11 total 3-px error in val = 4.372\n",
            "MAX epoch 1 total test error = 6.373\n",
            "0.001\n",
            "epoch 12 total training loss = 1.033\n",
            "epoch 12 total 3-px error in val = 4.640\n",
            "MAX epoch 1 total test error = 6.373\n",
            "0.001\n",
            "epoch 13 total training loss = 0.942\n",
            "epoch 13 total 3-px error in val = 5.004\n",
            "MAX epoch 1 total test error = 6.373\n",
            "0.001\n",
            "epoch 14 total training loss = 0.875\n",
            "epoch 14 total 3-px error in val = 4.675\n",
            "MAX epoch 1 total test error = 6.373\n",
            "0.001\n",
            "epoch 15 total training loss = 0.896\n",
            "epoch 15 total 3-px error in val = 4.780\n",
            "MAX epoch 1 total test error = 6.373\n",
            "0.001\n",
            "epoch 16 total training loss = 0.913\n",
            "epoch 16 total 3-px error in val = 4.440\n",
            "MAX epoch 1 total test error = 6.373\n",
            "0.001\n",
            "Traceback (most recent call last):\n",
            "  File \"finetune.py\", line 206, in <module>\n",
            "    main()\n",
            "  File \"finetune.py\", line 172, in main\n",
            "    loss = train(imgL_crop,imgR_crop, disp_crop_L)\n",
            "  File \"finetune.py\", line 120, in train\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 245, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 147, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hATWD6ucp1OJ",
        "outputId": "b8feaccc-fd27-4519-be96-44daa10fbb87"
      },
      "source": [
        "!python finetune.py --maxdisp 192 \\\n",
        "                   --model stackhourglass \\\n",
        "                   --datatype 2015 \\\n",
        "                   --datapath training/ \\\n",
        "                   --epochs 300 \\\n",
        "                   --loadmodel pretrained_sceneflow.tar \\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Sequential(\n",
            "  (0): AvgPool2d(kernel_size=(64, 64), stride=(64, 64), padding=0)\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (2): ReLU(inplace=True)\n",
            ")\n",
            "Sequential(\n",
            "  (0): AvgPool2d(kernel_size=(32, 32), stride=(32, 32), padding=0)\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (2): ReLU(inplace=True)\n",
            ")\n",
            "Sequential(\n",
            "  (0): AvgPool2d(kernel_size=(16, 16), stride=(16, 16), padding=0)\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (2): ReLU(inplace=True)\n",
            ")\n",
            "Number of model parameters: 5224768\n",
            "0.001\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "epoch 1 total training loss = 2.736\n",
            "tcmalloc: large alloc 1392771072 bytes == 0x55c203460000 @  0x7f9c06091b6b 0x7f9c060b1379 0x7f9bb27aa25e 0x7f9bb27ab9d2 0x7f9bef48e8e6 0x7f9bef8f0dd9 0x7f9befdfb77a 0x7f9befdc6ef9 0x7f9befd7d657 0x7f9befc21929 0x7f9c015edc07 0x7f9c015ef584 0x7f9c015bca8c 0x55c16b228c25 0x55c16b1e97f2 0x55c16b25d63d 0x55c16b1eabd9 0x55c16b1eb231 0x55c16b25a1e6 0x55c16b257b0e 0x55c16b1eae11 0x55c16b22e029 0x55c16b1eb231 0x55c16b25a1e6 0x55c16b257b0e 0x55c16b1eae11 0x55c16b1eb231 0x55c16b25a1e6 0x55c16b257b0e 0x55c16b1eae11 0x55c16b22e029\n",
            "tcmalloc: large alloc 1392771072 bytes == 0x55c203460000 @  0x7f9c06091b6b 0x7f9c060b1379 0x7f9bb27aa25e 0x7f9bb27ab9d2 0x7f9bef48e8e6 0x7f9bef8f0dd9 0x7f9befdfb77a 0x7f9befdc6ef9 0x7f9befd7d657 0x7f9befc21929 0x7f9c015edc07 0x7f9c015ef584 0x7f9c015bca8c 0x55c16b228c25 0x55c16b1e97f2 0x55c16b25d63d 0x55c16b1eabd9 0x55c16b1eb231 0x55c16b25a1e6 0x55c16b257b0e 0x55c16b1eae11 0x55c16b22e029 0x55c16b1eb231 0x55c16b25a1e6 0x55c16b257b0e 0x55c16b1eae11 0x55c16b1eb231 0x55c16b25a1e6 0x55c16b257b0e 0x55c16b1eae11 0x55c16b22e029\n",
            "tcmalloc: large alloc 1392771072 bytes == 0x55c203460000 @  0x7f9c06091b6b 0x7f9c060b1379 0x7f9bb27aa25e 0x7f9bb27ab9d2 0x7f9bef48e8e6 0x7f9bef8f0dd9 0x7f9befdfb77a 0x7f9befdc6ef9 0x7f9befd7d657 0x7f9befc21929 0x7f9c015edc07 0x7f9c015ef584 0x7f9c015bca8c 0x55c16b228c25 0x55c16b1e97f2 0x55c16b25d63d 0x55c16b1eabd9 0x55c16b1eb231 0x55c16b25a1e6 0x55c16b257b0e 0x55c16b1eae11 0x55c16b22e029 0x55c16b1eb231 0x55c16b25a1e6 0x55c16b257b0e 0x55c16b1eae11 0x55c16b1eb231 0x55c16b25a1e6 0x55c16b257b0e 0x55c16b1eae11 0x55c16b22e029\n",
            "epoch 1 total 3-px error in val = 4.794\n",
            "MAX epoch 1 total test error = 4.794\n",
            "0.001\n",
            "epoch 2 total training loss = 1.515\n",
            "epoch 2 total 3-px error in val = 3.580\n",
            "MAX epoch 1 total test error = 4.794\n",
            "0.001\n",
            "epoch 3 total training loss = 1.512\n",
            "epoch 3 total 3-px error in val = 3.182\n",
            "MAX epoch 1 total test error = 4.794\n",
            "0.001\n",
            "epoch 4 total training loss = 1.208\n",
            "epoch 4 total 3-px error in val = 3.394\n",
            "MAX epoch 1 total test error = 4.794\n",
            "0.001\n",
            "epoch 5 total training loss = 1.206\n",
            "epoch 5 total 3-px error in val = 3.260\n",
            "MAX epoch 1 total test error = 4.794\n",
            "0.001\n",
            "epoch 6 total training loss = 1.168\n",
            "epoch 6 total 3-px error in val = 2.673\n",
            "MAX epoch 1 total test error = 4.794\n",
            "0.001\n",
            "epoch 7 total training loss = 1.074\n",
            "epoch 7 total 3-px error in val = 2.509\n",
            "MAX epoch 1 total test error = 4.794\n",
            "0.001\n",
            "epoch 8 total training loss = 1.059\n",
            "epoch 8 total 3-px error in val = 2.380\n",
            "MAX epoch 1 total test error = 4.794\n",
            "0.001\n",
            "epoch 9 total training loss = 1.004\n",
            "epoch 9 total 3-px error in val = 2.289\n",
            "MAX epoch 1 total test error = 4.794\n",
            "0.001\n",
            "epoch 10 total training loss = 1.022\n",
            "epoch 10 total 3-px error in val = 2.715\n",
            "MAX epoch 1 total test error = 4.794\n",
            "0.001\n",
            "epoch 11 total training loss = 0.976\n",
            "epoch 11 total 3-px error in val = 2.228\n",
            "MAX epoch 1 total test error = 4.794\n",
            "0.001\n",
            "epoch 12 total training loss = 0.900\n",
            "epoch 12 total 3-px error in val = 2.620\n",
            "MAX epoch 1 total test error = 4.794\n",
            "0.001\n",
            "epoch 13 total training loss = 0.854\n",
            "Traceback (most recent call last):\n",
            "  File \"finetune.py\", line 207, in <module>\n",
            "    main()\n",
            "  File \"finetune.py\", line 181, in main\n",
            "    test_loss = test(imgL,imgR, disp_L)\n",
            "  File \"finetune.py\", line 134, in test\n",
            "    output3 = model(imgL,imgR)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 165, in forward\n",
            "    return self.module(*inputs[0], **kwargs[0])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/NoDatasetNeeded/PSMNet Extension/models/stackhourglass.py\", line 155, in forward\n",
            "    pred3 = disparityregression(self.maxdisp)(pred3)\n",
            "  File \"/content/NoDatasetNeeded/PSMNet Extension/models/submodule.py\", line 48, in __init__\n",
            "    self.disp = torch.Tensor(np.reshape(np.array(range(maxdisp)),[1, maxdisp,1,1])).cuda()\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v9qtUMYY2dT",
        "outputId": "1795d7ab-e32d-433a-8531-5d04ba12eda2"
      },
      "source": [
        "!python finetune.py --maxdisp 192 \\\n",
        "                   --model stackhourglass \\\n",
        "                   --datatype 2015 \\\n",
        "                   --datapath training/ \\\n",
        "                   --epochs 20 \\\n",
        "                   --loadmodel pretrained_sceneflow.tar \\\n",
        "                   --savemodel freeze_top_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Sequential(\n",
            "  (0): AvgPool2d(kernel_size=(64, 64), stride=(64, 64), padding=0)\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (2): ReLU(inplace=True)\n",
            ")\n",
            "Sequential(\n",
            "  (0): AvgPool2d(kernel_size=(32, 32), stride=(32, 32), padding=0)\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (2): ReLU(inplace=True)\n",
            ")\n",
            "Sequential(\n",
            "  (0): AvgPool2d(kernel_size=(16, 16), stride=(16, 16), padding=0)\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (2): ReLU(inplace=True)\n",
            ")\n",
            "Number of model parameters: 5224768\n",
            "0.001\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "epoch 1 total training loss = 2.737\n",
            "tcmalloc: large alloc 1392771072 bytes == 0x55f0bacc4000 @  0x7fe0ea047b6b 0x7fe0ea067379 0x7fe09676025e 0x7fe0967619d2 0x7fe0d34448e6 0x7fe0d38a6dd9 0x7fe0d3db177a 0x7fe0d3d7cef9 0x7fe0d3d33657 0x7fe0d3bd7929 0x7fe0e55a3c07 0x7fe0e55a5584 0x7fe0e5572a8c 0x55f0220bcc25 0x55f02207d7f2 0x55f0220f163d 0x55f02207ebd9 0x55f02207f231 0x55f0220ee1e6 0x55f0220ebb0e 0x55f02207ee11 0x55f0220c2029 0x55f02207f231 0x55f0220ee1e6 0x55f0220ebb0e 0x55f02207ee11 0x55f02207f231 0x55f0220ee1e6 0x55f0220ebb0e 0x55f02207ee11 0x55f0220c2029\n",
            "tcmalloc: large alloc 1392771072 bytes == 0x55f0bacc4000 @  0x7fe0ea047b6b 0x7fe0ea067379 0x7fe09676025e 0x7fe0967619d2 0x7fe0d34448e6 0x7fe0d38a6dd9 0x7fe0d3db177a 0x7fe0d3d7cef9 0x7fe0d3d33657 0x7fe0d3bd7929 0x7fe0e55a3c07 0x7fe0e55a5584 0x7fe0e5572a8c 0x55f0220bcc25 0x55f02207d7f2 0x55f0220f163d 0x55f02207ebd9 0x55f02207f231 0x55f0220ee1e6 0x55f0220ebb0e 0x55f02207ee11 0x55f0220c2029 0x55f02207f231 0x55f0220ee1e6 0x55f0220ebb0e 0x55f02207ee11 0x55f02207f231 0x55f0220ee1e6 0x55f0220ebb0e 0x55f02207ee11 0x55f0220c2029\n",
            "tcmalloc: large alloc 1392771072 bytes == 0x55f0bacc4000 @  0x7fe0ea047b6b 0x7fe0ea067379 0x7fe09676025e 0x7fe0967619d2 0x7fe0d34448e6 0x7fe0d38a6dd9 0x7fe0d3db177a 0x7fe0d3d7cef9 0x7fe0d3d33657 0x7fe0d3bd7929 0x7fe0e55a3c07 0x7fe0e55a5584 0x7fe0e5572a8c 0x55f0220bcc25 0x55f02207d7f2 0x55f0220f163d 0x55f02207ebd9 0x55f02207f231 0x55f0220ee1e6 0x55f0220ebb0e 0x55f02207ee11 0x55f0220c2029 0x55f02207f231 0x55f0220ee1e6 0x55f0220ebb0e 0x55f02207ee11 0x55f02207f231 0x55f0220ee1e6 0x55f0220ebb0e 0x55f02207ee11 0x55f0220c2029\n",
            "epoch 1 total 3-px error in val = 4.778\n",
            "MAX epoch 1 total test error = 4.778\n",
            "0.001\n",
            "epoch 2 total training loss = 1.516\n",
            "epoch 2 total 3-px error in val = 3.568\n",
            "MAX epoch 1 total test error = 4.778\n",
            "0.001\n",
            "epoch 3 total training loss = 1.518\n",
            "epoch 3 total 3-px error in val = 3.263\n",
            "MAX epoch 1 total test error = 4.778\n",
            "0.001\n",
            "epoch 4 total training loss = 1.203\n",
            "epoch 4 total 3-px error in val = 3.278\n",
            "MAX epoch 1 total test error = 4.778\n",
            "0.001\n",
            "epoch 5 total training loss = 1.223\n",
            "epoch 5 total 3-px error in val = 3.127\n",
            "MAX epoch 1 total test error = 4.778\n",
            "0.001\n",
            "epoch 6 total training loss = 1.213\n",
            "epoch 6 total 3-px error in val = 2.817\n",
            "MAX epoch 1 total test error = 4.778\n",
            "0.001\n",
            "epoch 7 total training loss = 1.093\n",
            "epoch 7 total 3-px error in val = 2.689\n",
            "MAX epoch 1 total test error = 4.778\n",
            "0.001\n",
            "epoch 8 total training loss = 1.058\n",
            "epoch 8 total 3-px error in val = 2.483\n",
            "MAX epoch 1 total test error = 4.778\n",
            "0.001\n",
            "epoch 9 total training loss = 1.008\n",
            "epoch 9 total 3-px error in val = 2.253\n",
            "MAX epoch 1 total test error = 4.778\n",
            "0.001\n",
            "epoch 10 total training loss = 1.043\n",
            "epoch 10 total 3-px error in val = 2.801\n",
            "MAX epoch 1 total test error = 4.778\n",
            "0.001\n",
            "epoch 11 total training loss = 0.979\n",
            "epoch 11 total 3-px error in val = 2.309\n",
            "MAX epoch 1 total test error = 4.778\n",
            "0.001\n",
            "Traceback (most recent call last):\n",
            "  File \"finetune.py\", line 207, in <module>\n",
            "    main()\n",
            "  File \"finetune.py\", line 173, in main\n",
            "    loss = train(imgL_crop,imgR_crop, disp_crop_L)\n",
            "  File \"finetune.py\", line 121, in train\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 245, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 147, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "-KKJefglb8qm",
        "outputId": "fc79d889-d849-450b-e483-aa63241a7f08"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "  \n",
        "# create data\n",
        "y_non_frozen = [4.885, 3.583, 3.231, 3.150, 2.763, 2.598, 2.457, 2.359, 2.378, 2.538, 2.201]\n",
        "y_top1_frozen = [4.832, 3.541, 3.297, 3.317, 2.696, 2.669, 2.640, 2.381, 2.221, 2.667, 2.273]\n",
        "y_top2_frozen = [4.825, 3.566, 3.179, 3.169, 2.922, 2.633, 2.463, 2.375, 2.272, 2.754, 2.408]\n",
        "y_top3_frozen = [4.778, 3.568, 3.263, 3.278, 3.127, 2.817, 2.689, 2.483, 2.253, 2.801, 2.309]\n",
        "\n",
        "plt.plot(range(11), y_non_frozen, label = 'none frozen')\n",
        "plt.plot(range(11), y_top1_frozen , label = 'freeze kernel 64')\n",
        "plt.plot(range(11), y_top2_frozen , label = 'freeze kernel 64 and 32')\n",
        "plt.plot(range(11), y_top3_frozen , label = 'freeze kernel 64, 32 and 16')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et4C-gKxpfiR",
        "outputId": "2fd48c8e-3ec0-4526-c800-17834205a96a"
      },
      "source": [
        "!python finetune.py --maxdisp 192 \\\n",
        "                   --model stackhourglass \\\n",
        "                   --datatype 2015 \\\n",
        "                   --datapath training/ \\\n",
        "                   --epochs 20 \\\n",
        "                   --loadmodel pretrained_sceneflow.tar \\\n",
        "                   --savemodel freeze_top_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Sequential(\n",
            "  (0): AvgPool2d(kernel_size=(64, 64), stride=(64, 64), padding=0)\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (2): ReLU(inplace=True)\n",
            ")\n",
            "Sequential(\n",
            "  (0): AvgPool2d(kernel_size=(32, 32), stride=(32, 32), padding=0)\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (2): ReLU(inplace=True)\n",
            ")\n",
            "Number of model parameters: 5224768\n",
            "0.001\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "epoch 1 total training loss = 2.736\n",
            "tcmalloc: large alloc 1392771072 bytes == 0x561067b9e000 @  0x7f3522e11b6b 0x7f3522e31379 0x7f34cf52a25e 0x7f34cf52b9d2 0x7f350c20e8e6 0x7f350c670dd9 0x7f350cb7b77a 0x7f350cb46ef9 0x7f350cafd657 0x7f350c9a1929 0x7f351e36dc07 0x7f351e36f584 0x7f351e33ca8c 0x560fcf1d8c25 0x560fcf1997f2 0x560fcf20d63d 0x560fcf19abd9 0x560fcf19b231 0x560fcf20a1e6 0x560fcf207b0e 0x560fcf19ae11 0x560fcf1de029 0x560fcf19b231 0x560fcf20a1e6 0x560fcf207b0e 0x560fcf19ae11 0x560fcf19b231 0x560fcf20a1e6 0x560fcf207b0e 0x560fcf19ae11 0x560fcf1de029\n",
            "tcmalloc: large alloc 1392771072 bytes == 0x561067b9e000 @  0x7f3522e11b6b 0x7f3522e31379 0x7f34cf52a25e 0x7f34cf52b9d2 0x7f350c20e8e6 0x7f350c670dd9 0x7f350cb7b77a 0x7f350cb46ef9 0x7f350cafd657 0x7f350c9a1929 0x7f351e36dc07 0x7f351e36f584 0x7f351e33ca8c 0x560fcf1d8c25 0x560fcf1997f2 0x560fcf20d63d 0x560fcf19abd9 0x560fcf19b231 0x560fcf20a1e6 0x560fcf207b0e 0x560fcf19ae11 0x560fcf1de029 0x560fcf19b231 0x560fcf20a1e6 0x560fcf207b0e 0x560fcf19ae11 0x560fcf19b231 0x560fcf20a1e6 0x560fcf207b0e 0x560fcf19ae11 0x560fcf1de029\n",
            "tcmalloc: large alloc 1392771072 bytes == 0x561067b9e000 @  0x7f3522e11b6b 0x7f3522e31379 0x7f34cf52a25e 0x7f34cf52b9d2 0x7f350c20e8e6 0x7f350c670dd9 0x7f350cb7b77a 0x7f350cb46ef9 0x7f350cafd657 0x7f350c9a1929 0x7f351e36dc07 0x7f351e36f584 0x7f351e33ca8c 0x560fcf1d8c25 0x560fcf1997f2 0x560fcf20d63d 0x560fcf19abd9 0x560fcf19b231 0x560fcf20a1e6 0x560fcf207b0e 0x560fcf19ae11 0x560fcf1de029 0x560fcf19b231 0x560fcf20a1e6 0x560fcf207b0e 0x560fcf19ae11 0x560fcf19b231 0x560fcf20a1e6 0x560fcf207b0e 0x560fcf19ae11 0x560fcf1de029\n",
            "epoch 1 total 3-px error in val = 4.825\n",
            "MAX epoch 1 total test error = 4.825\n",
            "0.001\n",
            "epoch 2 total training loss = 1.516\n",
            "epoch 2 total 3-px error in val = 3.566\n",
            "MAX epoch 1 total test error = 4.825\n",
            "0.001\n",
            "epoch 3 total training loss = 1.516\n",
            "epoch 3 total 3-px error in val = 3.179\n",
            "MAX epoch 1 total test error = 4.825\n",
            "0.001\n",
            "epoch 4 total training loss = 1.200\n",
            "epoch 4 total 3-px error in val = 3.169\n",
            "MAX epoch 1 total test error = 4.825\n",
            "0.001\n",
            "epoch 5 total training loss = 1.225\n",
            "epoch 5 total 3-px error in val = 2.922\n",
            "MAX epoch 1 total test error = 4.825\n",
            "0.001\n",
            "epoch 6 total training loss = 1.176\n",
            "epoch 6 total 3-px error in val = 2.633\n",
            "MAX epoch 1 total test error = 4.825\n",
            "0.001\n",
            "epoch 7 total training loss = 1.078\n",
            "epoch 7 total 3-px error in val = 2.463\n",
            "MAX epoch 1 total test error = 4.825\n",
            "0.001\n",
            "epoch 8 total training loss = 1.069\n",
            "epoch 8 total 3-px error in val = 2.375\n",
            "MAX epoch 1 total test error = 4.825\n",
            "0.001\n",
            "epoch 9 total training loss = 1.018\n",
            "epoch 9 total 3-px error in val = 2.272\n",
            "MAX epoch 1 total test error = 4.825\n",
            "0.001\n",
            "epoch 10 total training loss = 1.038\n",
            "epoch 10 total 3-px error in val = 2.754\n",
            "MAX epoch 1 total test error = 4.825\n",
            "0.001\n",
            "epoch 11 total training loss = 0.989\n",
            "epoch 11 total 3-px error in val = 2.408\n",
            "MAX epoch 1 total test error = 4.825\n",
            "0.001\n",
            "Traceback (most recent call last):\n",
            "  File \"finetune.py\", line 207, in <module>\n",
            "    main()\n",
            "  File \"finetune.py\", line 173, in main\n",
            "    loss = train(imgL_crop,imgR_crop, disp_crop_L)\n",
            "  File \"finetune.py\", line 121, in train\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 245, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 147, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpAWU64gx_1S",
        "outputId": "eaac851d-fa6c-43cf-99d9-b48e7535109f"
      },
      "source": [
        "!python finetune.py --maxdisp 192 \\\n",
        "                   --model stackhourglass \\\n",
        "                   --datatype 2015 \\\n",
        "                   --datapath training/ \\\n",
        "                   --epochs 20 \\\n",
        "                   --loadmodel pretrained_sceneflow.tar \\\n",
        "                   --savemodel freeze_top_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Sequential(\n",
            "  (0): AvgPool2d(kernel_size=(64, 64), stride=(64, 64), padding=0)\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (2): ReLU(inplace=True)\n",
            ")\n",
            "Number of model parameters: 5224768\n",
            "0.001\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "epoch 1 total training loss = 2.737\n",
            "tcmalloc: large alloc 1392771072 bytes == 0x563706f20000 @  0x7f9dc8f57b6b 0x7f9dc8f77379 0x7f9d7567025e 0x7f9d756719d2 0x7f9db23548e6 0x7f9db27b6dd9 0x7f9db2cc177a 0x7f9db2c8cef9 0x7f9db2c43657 0x7f9db2ae7929 0x7f9dc44b3c07 0x7f9dc44b5584 0x7f9dc4482a8c 0x56366f643c25 0x56366f6047f2 0x56366f67863d 0x56366f605bd9 0x56366f606231 0x56366f6751e6 0x56366f672b0e 0x56366f605e11 0x56366f649029 0x56366f606231 0x56366f6751e6 0x56366f672b0e 0x56366f605e11 0x56366f606231 0x56366f6751e6 0x56366f672b0e 0x56366f605e11 0x56366f649029\n",
            "tcmalloc: large alloc 1392771072 bytes == 0x563706f20000 @  0x7f9dc8f57b6b 0x7f9dc8f77379 0x7f9d7567025e 0x7f9d756719d2 0x7f9db23548e6 0x7f9db27b6dd9 0x7f9db2cc177a 0x7f9db2c8cef9 0x7f9db2c43657 0x7f9db2ae7929 0x7f9dc44b3c07 0x7f9dc44b5584 0x7f9dc4482a8c 0x56366f643c25 0x56366f6047f2 0x56366f67863d 0x56366f605bd9 0x56366f606231 0x56366f6751e6 0x56366f672b0e 0x56366f605e11 0x56366f649029 0x56366f606231 0x56366f6751e6 0x56366f672b0e 0x56366f605e11 0x56366f606231 0x56366f6751e6 0x56366f672b0e 0x56366f605e11 0x56366f649029\n",
            "tcmalloc: large alloc 1392771072 bytes == 0x563706f20000 @  0x7f9dc8f57b6b 0x7f9dc8f77379 0x7f9d7567025e 0x7f9d756719d2 0x7f9db23548e6 0x7f9db27b6dd9 0x7f9db2cc177a 0x7f9db2c8cef9 0x7f9db2c43657 0x7f9db2ae7929 0x7f9dc44b3c07 0x7f9dc44b5584 0x7f9dc4482a8c 0x56366f643c25 0x56366f6047f2 0x56366f67863d 0x56366f605bd9 0x56366f606231 0x56366f6751e6 0x56366f672b0e 0x56366f605e11 0x56366f649029 0x56366f606231 0x56366f6751e6 0x56366f672b0e 0x56366f605e11 0x56366f606231 0x56366f6751e6 0x56366f672b0e 0x56366f605e11 0x56366f649029\n",
            "epoch 1 total 3-px error in val = 4.832\n",
            "MAX epoch 1 total test error = 4.832\n",
            "0.001\n",
            "epoch 2 total training loss = 1.513\n",
            "epoch 2 total 3-px error in val = 3.541\n",
            "MAX epoch 1 total test error = 4.832\n",
            "0.001\n",
            "epoch 3 total training loss = 1.526\n",
            "epoch 3 total 3-px error in val = 3.297\n",
            "MAX epoch 1 total test error = 4.832\n",
            "0.001\n",
            "epoch 4 total training loss = 1.209\n",
            "epoch 4 total 3-px error in val = 3.317\n",
            "MAX epoch 1 total test error = 4.832\n",
            "0.001\n",
            "epoch 5 total training loss = 1.295\n",
            "epoch 5 total 3-px error in val = 2.696\n",
            "MAX epoch 1 total test error = 4.832\n",
            "0.001\n",
            "epoch 6 total training loss = 1.178\n",
            "epoch 6 total 3-px error in val = 2.669\n",
            "MAX epoch 1 total test error = 4.832\n",
            "0.001\n",
            "epoch 7 total training loss = 1.095\n",
            "epoch 7 total 3-px error in val = 2.640\n",
            "MAX epoch 1 total test error = 4.832\n",
            "0.001\n",
            "epoch 8 total training loss = 1.060\n",
            "epoch 8 total 3-px error in val = 2.381\n",
            "MAX epoch 1 total test error = 4.832\n",
            "0.001\n",
            "epoch 9 total training loss = 1.012\n",
            "epoch 9 total 3-px error in val = 2.221\n",
            "MAX epoch 1 total test error = 4.832\n",
            "0.001\n",
            "epoch 10 total training loss = 1.043\n",
            "epoch 10 total 3-px error in val = 2.667\n",
            "MAX epoch 1 total test error = 4.832\n",
            "0.001\n",
            "epoch 11 total training loss = 0.990\n",
            "epoch 11 total 3-px error in val = 2.273\n",
            "MAX epoch 1 total test error = 4.832\n",
            "0.001\n",
            "epoch 12 total training loss = 0.907\n",
            "epoch 12 total 3-px error in val = 2.591\n",
            "MAX epoch 1 total test error = 4.832\n",
            "0.001\n",
            "Traceback (most recent call last):\n",
            "  File \"finetune.py\", line 207, in <module>\n",
            "    main()\n",
            "  File \"finetune.py\", line 173, in main\n",
            "    loss = train(imgL_crop,imgR_crop, disp_crop_L)\n",
            "  File \"finetune.py\", line 111, in train\n",
            "    output1, output2, output3 = model(imgL,imgR)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 165, in forward\n",
            "    return self.module(*inputs[0], **kwargs[0])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/NoDatasetNeeded/PSMNet Extension/models/stackhourglass.py\", line 143, in forward\n",
            "    pred1 = disparityregression(self.maxdisp)(pred1)\n",
            "  File \"/content/NoDatasetNeeded/PSMNet Extension/models/submodule.py\", line 48, in __init__\n",
            "    self.disp = torch.Tensor(np.reshape(np.array(range(maxdisp)),[1, maxdisp,1,1])).cuda()\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJGAf-r3eOtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33f6554-24bc-4058-e066-4fa318ee20a3"
      },
      "source": [
        "import  torch\n",
        "from models import *\n",
        "import torch.nn as nn\n",
        "model = stackhourglass(192)\n",
        "model = nn.DataParallel(model)\n",
        "model.cuda()\n",
        "state_dict = torch.load('pretrained_sceneflow.tar')\n",
        "model.load_state_dict(state_dict['state_dict'])\n",
        "for i, child in enumerate(model.children()):\n",
        "  if i == 0:\n",
        "      for j, childchild in enumerate(child.children()):\n",
        "        if j == 1 or j == 2:\n",
        "            for param in childchild.parameters():\n",
        "              param.requires_grad = False\n",
        "            print(childchild)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Sequential(\n",
            "    (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (3): ReLU(inplace=True)\n",
            ")\n",
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Sequential(\n",
            "    (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqRL4O115fIH",
        "outputId": "a7f1321a-1cde-4461-c0dc-24d3acde0f8d"
      },
      "source": [
        "!python submission.py --maxdisp 192 \\\n",
        "                   --model stackhourglass \\\n",
        "                   --KITTI 2015\\\n",
        "                   --datapath ./training/ \\\n",
        "                   --loadmodel finetune_9.tar \\\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of model parameters: 5224768\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "time = 1.01\n",
            "time = 0.91\n",
            "time = 0.91\n",
            "time = 0.92\n",
            "time = 0.92\n",
            "time = 0.92\n",
            "time = 0.92\n",
            "time = 0.92\n",
            "time = 0.93\n",
            "time = 0.92\n",
            "time = 0.92\n",
            "time = 0.93\n",
            "time = 0.92\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.94\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.94\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.93\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.91\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.95\n",
            "time = 0.94\n",
            "time = 0.95\n",
            "time = 0.95\n",
            "time = 0.91\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.95\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.94\n",
            "time = 0.95\n",
            "time = 0.95\n",
            "time = 0.95\n",
            "time = 0.95\n",
            "time = 0.95\n",
            "time = 0.95\n",
            "time = 0.95\n",
            "time = 0.95\n",
            "time = 0.96\n",
            "time = 0.95\n",
            "time = 0.95\n",
            "time = 0.95\n",
            "time = 0.95\n",
            "time = 0.94\n",
            "time = 0.96\n",
            "time = 0.95\n",
            "time = 0.96\n",
            "time = 0.95\n",
            "time = 0.95\n",
            "time = 0.95\n",
            "time = 0.96\n",
            "time = 0.95\n",
            "time = 0.95\n",
            "time = 0.96\n",
            "time = 0.95\n",
            "time = 0.96\n",
            "time = 0.95\n",
            "time = 0.96\n",
            "time = 0.95\n",
            "time = 0.95\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.95\n",
            "time = 0.95\n",
            "time = 0.96\n",
            "time = 0.95\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.95\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.95\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.97\n",
            "time = 0.95\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.97\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "time = 0.96\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 496, in _save\n",
            "AttributeError: '_idat' object has no attribute 'fileno'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"submission.py\", line 117, in <module>\n",
            "    main()\n",
            "  File \"submission.py\", line 113, in main\n",
            "    img.save(test_left_img[inx].split('/')[-1])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2134, in save\n",
            "    save_handler(self, fp, filename)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/PngImagePlugin.py\", line 1291, in _save\n",
            "    ImageFile._save(im, _idat(fp, chunk), [(\"zip\", (0, 0) + im.size, 0, rawmode)])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 510, in _save\n",
            "    l, s, d = e.encode(bufsize)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWqlF-Zx8tja"
      },
      "source": [
        "!python finetune.py --maxdisp 192 \\\n",
        "                   --model stackhourglass \\\n",
        "                   --datatype 2015 \\\n",
        "                   --datapath training/ \\\n",
        "                   --epochs 20 \\\n",
        "                   --loadmodel pretrained_sceneflow.tar \\"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}